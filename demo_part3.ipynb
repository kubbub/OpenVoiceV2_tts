{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi-Accent and Multi-Lingual Voice Clone Demo with MeloTTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/anaconda3/envs/openvoicev2/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Importing the dtw module. When using in academic works please cite:\n",
      "  T. Giorgino. Computing and Visualizing Dynamic Time Warping Alignments in R: The dtw Package.\n",
      "  J. Stat. Soft., doi:10.18637/jss.v031.i07.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "from openvoice import se_extractor\n",
    "from openvoice.api import ToneColorConverter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialization\n",
    "\n",
    "In this example, we will use the checkpoints from OpenVoiceV2. OpenVoiceV2 is trained with more aggressive augmentations and thus demonstrate better robustness in some cases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded checkpoint 'checkpoints/converter/checkpoint.pth'\n",
      "missing/unexpected keys: [] []\n"
     ]
    }
   ],
   "source": [
    "ckpt_converter = 'checkpoints/converter'\n",
    "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "output_dir = 'outputs_v2'\n",
    "\n",
    "tone_color_converter = ToneColorConverter(f'{ckpt_converter}/config.json', device=device)\n",
    "tone_color_converter.load_ckpt(f'{ckpt_converter}/checkpoint.pth')\n",
    "\n",
    "os.makedirs(output_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Obtain Tone Color Embedding\n",
    "We only extract the tone color embedding for the target speaker. The source tone color embeddings can be directly loaded from `checkpoints_v2/ses` folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenVoice version: v1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Estimating duration from bitrate, this may be inaccurate\n"
     ]
    }
   ],
   "source": [
    "\n",
    "reference_speaker = 'resources/demo_speaker2.mp3' # This is the voice you want to clone\n",
    "target_se, audio_name = se_extractor.get_se(reference_speaker, tone_color_converter, vad=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Use MeloTTS as Base Speakers\n",
    "\n",
    "MeloTTS is a high-quality multi-lingual text-to-speech library by @MyShell.ai, supporting languages including English (American, British, Indian, Australian, Default), Spanish, French, Chinese, Japanese, Korean. In the following example, we will use the models in MeloTTS as the base speakers. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available speaker keys: ['EN-US', 'EN-BR', 'EN_INDIA', 'EN-AU', 'EN-Default']\n",
      "Using speaker: EN-US\n",
      " > Text split to sentences.\n",
      "The integration of AI into various industries has driven significant advancements in hardware technology. PC manufacturers are now offering AI-specific hardware to enhance end-user devices. Field-Programmable Gate Arrays FPGAs and Application-Specific Integrated Circuits ASICs,\n",
      "such as Google's Tensor Processing Units TPUs, are being utilized to accelerate machine learning workloads. These hardware solutions are particularly useful in edge computing scenarios, where AI capabilities need to be deployed close to the data source to reduce latency and improve decision-making.\n",
      "Microsoft has introduced Copilot+ PCs, which feature new silicon capable of performing over 40 trillion operations per second, enhancing AI capabilities such as real-time image generation and language translation. Apple has also integrated Apple silicon to handle advanced AI processing.\n",
      "These developments reflect the growing trend of AI processing moving closer to the user and the edge, rather than relying solely on cloud-based solutions.\n",
      " > ===========================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/4 [00:00<?, ?it/s]Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "100%|██████████| 4/4 [00:20<00:00,  5.06s/it]\n"
     ]
    }
   ],
   "source": [
    "from melo.api import TTS\n",
    "import torch\n",
    "\n",
    "output_dir = \"outputs_v2\"  # Replace with your actual output directory\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "text = \"The integration of AI into various industries has driven significant advancements in hardware technology. PC manufacturers are now offering AI-specific hardware to enhance end-user devices. Field-Programmable Gate Arrays (FPGAs) and Application-Specific Integrated Circuits (ASICs), such as Google's Tensor Processing Units (TPUs), are being utilized to accelerate machine learning workloads. These hardware solutions are particularly useful in edge computing scenarios, where AI capabilities need to be deployed close to the data source to reduce latency and improve decision-making. Microsoft has introduced Copilot+ PCs, which feature new silicon capable of performing over 40 trillion operations per second, enhancing AI capabilities such as real-time image generation and language translation. Apple has also integrated Apple silicon to handle advanced AI processing. These developments reflect the growing trend of AI processing moving closer to the user and the edge, rather than relying solely on cloud-based solutions.\"\n",
    "src_path = f\"{output_dir}/tmp.wav\"\n",
    "speed = 1.0\n",
    "\n",
    "model = TTS(language=\"EN\", device=device)\n",
    "speaker_ids = model.hps.data.spk2id\n",
    "\n",
    "# Print available speaker keys\n",
    "print(\"Available speaker keys:\", list(speaker_ids.keys()))\n",
    "\n",
    "# Try to find an appropriate English speaker\n",
    "english_speakers = [key for key in speaker_ids.keys() if key.startswith(\"EN\")]\n",
    "\n",
    "if not english_speakers:\n",
    "    raise ValueError(\n",
    "        \"No English speaker found. Available speakers: \" + \", \".join(speaker_ids.keys())\n",
    "    )\n",
    "\n",
    "# Use the first available English speaker\n",
    "speaker_key = english_speakers[0]\n",
    "speaker_id = speaker_ids[speaker_key]\n",
    "\n",
    "print(f\"Using speaker: {speaker_key}\")\n",
    "\n",
    "source_se = torch.load(\n",
    "    f'checkpoints_v2/base_speakers/ses/{speaker_key.lower().replace(\"_\", \"-\")}.pth',\n",
    "    map_location=device,\n",
    ")\n",
    "model.tts_to_file(text, speaker_id, src_path, speed=speed)\n",
    "save_path = f'{output_dir}/output_v2_{speaker_key.lower().replace(\"_\", \"-\")}.wav'\n",
    "\n",
    "# Run the tone color converter\n",
    "encode_message = \"@MyShell\"\n",
    "tone_color_converter.convert(\n",
    "    audio_src_path=src_path,\n",
    "    src_se=source_se,\n",
    "    tgt_se=target_se,\n",
    "    output_path=save_path,\n",
    "    message=encode_message,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "melo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
